{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Fine-Tuning Data Preparation\n",
        "## RAG vs Fine-Tuning: A Comparative Study for Legal QA\n",
        "\n",
        "This notebook prepares the Indian Legal dataset for fine-tuning the Mistral model.\n",
        "\n",
        "**Dataset**: [ninadn/indian-legal](https://huggingface.co/datasets/ninadn/indian-legal)  \n",
        "**Model**: Mistral-7B-Instruct-v0.1  \n",
        "**Task**: Legal Question Answering  \n",
        "**Approach**: Instruction Tuning with QLoRA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for plots\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Create directories\n",
        "os.makedirs('./processed_data', exist_ok=True)\n",
        "os.makedirs('./models', exist_ok=True)\n",
        "\n",
        "print(\"üì¶ Environment setup complete!\")\n",
        "print(\"üîç Ready to process Indian Legal dataset for Mistral fine-tuning\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 2. Load Indian Legal Dataset from Hugging Face\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Indian Legal dataset from Hugging Face\n",
        "print(\"üîÑ Loading Indian Legal Dataset from Hugging Face...\")\n",
        "try:\n",
        "    dataset = load_dataset(\"ninadn/indian-legal\")\n",
        "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
        "    print(f\"üìä Dataset structure: {dataset}\")\n",
        "    \n",
        "    # Convert to pandas for analysis\n",
        "    train_df = pd.DataFrame(dataset['train'])\n",
        "    test_df = pd.DataFrame(dataset['test'])\n",
        "    \n",
        "    print(f\"\\nüìà Dataset Statistics:\")\n",
        "    print(f\"  Training samples: {len(train_df):,}\")\n",
        "    print(f\"  Test samples: {len(test_df):,}\")\n",
        "    print(f\"  Total samples: {len(train_df) + len(test_df):,}\")\n",
        "    print(f\"  Columns: {list(train_df.columns)}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading dataset: {e}\")\n",
        "    print(\"Please check your internet connection and Hugging Face access\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 3. Exploratory Data Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze the text data\n",
        "print(\"üìä Analyzing Legal Documents...\")\n",
        "\n",
        "# Calculate text statistics\n",
        "train_df['text_length'] = train_df['Text'].str.len()\n",
        "test_df['text_length'] = test_df['Text'].str.len()\n",
        "\n",
        "# Display basic statistics\n",
        "print(\"\\nüìè Text Length Statistics:\")\n",
        "print(\"=\" * 50)\n",
        "stats_data = {\n",
        "    'Dataset': ['Training', 'Test'],\n",
        "    'Count': [len(train_df), len(test_df)],\n",
        "    'Mean Length': [train_df['text_length'].mean(), test_df['text_length'].mean()],\n",
        "    'Median Length': [train_df['text_length'].median(), test_df['text_length'].median()],\n",
        "    'Min Length': [train_df['text_length'].min(), test_df['text_length'].min()],\n",
        "    'Max Length': [train_df['text_length'].max(), test_df['text_length'].max()],\n",
        "    'Std Dev': [train_df['text_length'].std(), test_df['text_length'].std()]\n",
        "}\n",
        "\n",
        "stats_df = pd.DataFrame(stats_data)\n",
        "print(stats_df.round(2).to_string(index=False))\n",
        "\n",
        "# Sample documents\n",
        "print(f\"\\nüìù Sample Legal Documents:\")\n",
        "print(\"=\" * 80)\n",
        "for i, (idx, row) in enumerate(train_df.head(2).iterrows()):\n",
        "    print(f\"\\nüèõÔ∏è Document {i+1} ({len(row['Text'])} characters):\")\n",
        "    print(\"-\" * 40)\n",
        "    # Show first 600 characters\n",
        "    preview = row['Text'][:600].replace('\\n', ' ').strip()\n",
        "    print(f\"{preview}...\")\n",
        "    print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize text length distributions\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Indian Legal Dataset - Text Length Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Training set histogram\n",
        "axes[0, 0].hist(train_df['text_length'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].set_title(f'Training Set Distribution (n={len(train_df):,})')\n",
        "axes[0, 0].set_xlabel('Text Length (characters)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].axvline(train_df['text_length'].mean(), color='red', linestyle='--', \n",
        "                   label=f'Mean: {train_df[\"text_length\"].mean():.0f}')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# Test set histogram  \n",
        "axes[0, 1].hist(test_df['text_length'], bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "axes[0, 1].set_title(f'Test Set Distribution (n={len(test_df):,})')\n",
        "axes[0, 1].set_xlabel('Text Length (characters)')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].axvline(test_df['text_length'].mean(), color='red', linestyle='--',\n",
        "                   label=f'Mean: {test_df[\"text_length\"].mean():.0f}')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# Box plot comparison\n",
        "box_data = [train_df['text_length'], test_df['text_length']]\n",
        "box_plot = axes[1, 0].boxplot(box_data, labels=['Training', 'Test'], patch_artist=True)\n",
        "box_plot['boxes'][0].set_facecolor('skyblue')\n",
        "box_plot['boxes'][1].set_facecolor('lightcoral')\n",
        "axes[1, 0].set_title('Text Length Comparison')\n",
        "axes[1, 0].set_ylabel('Text Length (characters)')\n",
        "\n",
        "# Log scale for better visualization of distribution\n",
        "axes[1, 1].hist(train_df['text_length'], bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "axes[1, 1].set_yscale('log')\n",
        "axes[1, 1].set_title('Training Set - Log Scale')\n",
        "axes[1, 1].set_xlabel('Text Length (characters)')\n",
        "axes[1, 1].set_ylabel('Frequency (log scale)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print percentiles for better understanding\n",
        "print(f\"\\nüìä Training Set Text Length Percentiles:\")\n",
        "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
        "for p in percentiles:\n",
        "    val = np.percentile(train_df['text_length'], p)\n",
        "    print(f\"  {p}th percentile: {val:.0f} characters\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 4. Generate Question-Answer Pairs for Legal Documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Fine-Tuning Data Preparation\n",
        "## RAG vs Fine-Tuning: A Comparative Study\n",
        "\n",
        "This notebook prepares the Indian Legal dataset for fine-tuning the Mistral model.\n",
        "\n",
        "**Dataset**: ninadn/indian-legal\n",
        "**Model**: Mistral-7B\n",
        "**Task**: Legal Question Answering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset, Dataset\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Create directories\n",
        "os.makedirs('./processed_data', exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Load and Explore Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Indian Legal dataset\n",
        "print(\"Loading Indian Legal Dataset...\")\n",
        "dataset = load_dataset(\"ninadn/indian-legal\")\n",
        "print(f\"Dataset loaded successfully!\")\n",
        "print(f\"Dataset structure: {dataset}\")\n",
        "\n",
        "# Convert to pandas for easier manipulation\n",
        "train_df = pd.DataFrame(dataset['train'])\n",
        "test_df = pd.DataFrame(dataset['test'])\n",
        "\n",
        "print(f\"\\nTrain set size: {len(train_df)}\")\n",
        "print(f\"Test set size: {len(test_df)}\")\n",
        "print(f\"\\nColumns: {train_df.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample data\n",
        "print(\"Sample data from training set:\")\n",
        "print(\"=\" * 50)\n",
        "for i in range(2):\n",
        "    print(f\"\\n--- Sample {i+1} ---\")\n",
        "    print(f\"Text length: {len(train_df.iloc[i]['Text'])} characters\")\n",
        "    print(f\"First 500 characters:\")\n",
        "    print(train_df.iloc[i]['Text'][:500] + \"...\")\n",
        "    print(\"\\n\" + \"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Data Analysis and Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze text lengths\n",
        "train_df['text_length'] = train_df['Text'].str.len()\n",
        "test_df['text_length'] = test_df['Text'].str.len()\n",
        "\n",
        "# Basic statistics\n",
        "print(\"Text Length Statistics:\")\n",
        "print(\"=\" * 30)\n",
        "print(f\"Train set:\")\n",
        "print(f\"  Mean: {train_df['text_length'].mean():.2f} characters\")\n",
        "print(f\"  Median: {train_df['text_length'].median():.2f} characters\")\n",
        "print(f\"  Min: {train_df['text_length'].min()} characters\")\n",
        "print(f\"  Max: {train_df['text_length'].max()} characters\")\n",
        "print(f\"  Std: {train_df['text_length'].std():.2f} characters\")\n",
        "\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Mean: {test_df['text_length'].mean():.2f} characters\")\n",
        "print(f\"  Median: {test_df['text_length'].median():.2f} characters\")\n",
        "print(f\"  Min: {test_df['text_length'].min()} characters\")\n",
        "print(f\"  Max: {test_df['text_length'].max()} characters\")\n",
        "print(f\"  Std: {test_df['text_length'].std():.2f} characters\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize text length distribution\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Text Length Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Histogram for train set\n",
        "axes[0, 0].hist(train_df['text_length'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Train Set - Text Length Distribution')\n",
        "axes[0, 0].set_xlabel('Text Length (characters)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "\n",
        "# Histogram for test set\n",
        "axes[0, 1].hist(test_df['text_length'], bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "axes[0, 1].set_title('Test Set - Text Length Distribution')\n",
        "axes[0, 1].set_xlabel('Text Length (characters)')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "\n",
        "# Box plot comparison\n",
        "box_data = [train_df['text_length'], test_df['text_length']]\n",
        "axes[1, 0].boxplot(box_data, labels=['Train', 'Test'])\n",
        "axes[1, 0].set_title('Text Length Comparison')\n",
        "axes[1, 0].set_ylabel('Text Length (characters)')\n",
        "\n",
        "# Log scale histogram for better visualization\n",
        "axes[1, 1].hist(train_df['text_length'], bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "axes[1, 1].set_yscale('log')\n",
        "axes[1, 1].set_title('Train Set - Text Length (Log Scale)')\n",
        "axes[1, 1].set_xlabel('Text Length (characters)')\n",
        "axes[1, 1].set_ylabel('Frequency (log scale)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Text Processing and QA Pair Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_legal_text(text):\n",
        "    \"\"\"\n",
        "    Clean and preprocess legal text for fine-tuning\n",
        "    \"\"\"\n",
        "    # Remove excessive whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    # Remove special characters but keep legal punctuation\n",
        "    text = re.sub(r'[^\\w\\s.,;:()\\[\\]\"\\'\"-]', '', text)\n",
        "    \n",
        "    # Normalize quotes\n",
        "    text = re.sub(r'[\"\"'']', '\"', text)\n",
        "    \n",
        "    # Strip leading/trailing whitespace\n",
        "    text = text.strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "def create_qa_pairs(text, max_length=1500):\n",
        "    \"\"\"\n",
        "    Create question-answer pairs from legal text\n",
        "    \"\"\"\n",
        "    qa_pairs = []\n",
        "    \n",
        "    # Question templates for legal documents\n",
        "    question_templates = [\n",
        "        \"What is the main legal issue discussed in this case?\",\n",
        "        \"What are the key provisions and clauses mentioned?\",\n",
        "        \"What is the court's decision or ruling?\",\n",
        "        \"What are the relevant legal sections cited?\",\n",
        "        \"What are the rights and obligations of the parties?\",\n",
        "        \"What legal principles or precedents are discussed?\",\n",
        "        \"What are the terms and conditions mentioned?\",\n",
        "        \"What penalties or consequences are discussed?\"\n",
        "    ]\n",
        "    \n",
        "    # Clean the text\n",
        "    cleaned_text = clean_legal_text(text)\n",
        "    \n",
        "    # If text is too long, create multiple chunks\n",
        "    if len(cleaned_text) > max_length:\n",
        "        sentences = cleaned_text.split('. ')\n",
        "        current_chunk = \"\"\n",
        "        \n",
        "        for sentence in sentences:\n",
        "            if len(current_chunk + sentence) <= max_length:\n",
        "                current_chunk += sentence + \". \"\n",
        "            else:\n",
        "                if current_chunk:\n",
        "                    # Create QA pairs for this chunk\n",
        "                    for i, question in enumerate(question_templates[:3]):  # Limit to 3 per chunk\n",
        "                        qa_pairs.append({\n",
        "                            'question': question,\n",
        "                            'context': current_chunk.strip(),\n",
        "                            'answer': current_chunk.strip()\n",
        "                        })\n",
        "                current_chunk = sentence + \". \"\n",
        "        \n",
        "        # Handle remaining chunk\n",
        "        if current_chunk:\n",
        "            for i, question in enumerate(question_templates[:3]):\n",
        "                qa_pairs.append({\n",
        "                    'question': question,\n",
        "                    'context': current_chunk.strip(),\n",
        "                    'answer': current_chunk.strip()\n",
        "                })\n",
        "    else:\n",
        "        # Create QA pairs for the entire text\n",
        "        for i, question in enumerate(question_templates[:4]):  # More questions for shorter texts\n",
        "            qa_pairs.append({\n",
        "                'question': question,\n",
        "                'context': cleaned_text,\n",
        "                'answer': cleaned_text\n",
        "            })\n",
        "    \n",
        "    return qa_pairs\n",
        "\n",
        "# Apply cleaning and generate QA pairs\n",
        "print(\"Processing legal documents and generating QA pairs...\")\n",
        "all_qa_pairs = []\n",
        "\n",
        "# Process a subset for initial development\n",
        "sample_size = min(100, len(train_df))  # Start with 100 documents\n",
        "for idx, row in tqdm(train_df.head(sample_size).iterrows(), total=sample_size, desc=\"Processing documents\"):\n",
        "    qa_pairs = create_qa_pairs(row['Text'])\n",
        "    all_qa_pairs.extend(qa_pairs)\n",
        "\n",
        "print(f\"Generated {len(all_qa_pairs)} question-answer pairs from {sample_size} documents\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Format Data for Instruction Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load tokenizer to check token lengths\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def format_for_instruction_tuning(qa_pair):\n",
        "    \"\"\"\n",
        "    Format QA pair for instruction tuning with Mistral\n",
        "    \"\"\"\n",
        "    # Truncate context and answer to reasonable lengths\n",
        "    context = qa_pair['context'][:1000] if len(qa_pair['context']) > 1000 else qa_pair['context']\n",
        "    answer = qa_pair['answer'][:800] if len(qa_pair['answer']) > 800 else qa_pair['answer']\n",
        "    \n",
        "    prompt = f\"\"\"<s>[INST] You are a legal assistant specializing in Indian law. Answer the following question based on the provided legal text.\n",
        "\n",
        "Question: {qa_pair['question']}\n",
        "\n",
        "Legal Text: {context} [/INST]\n",
        "\n",
        "Based on the legal text provided, {answer}</s>\"\"\"\n",
        "    \n",
        "    return prompt\n",
        "\n",
        "# Format all QA pairs\n",
        "print(\"Formatting data for instruction tuning...\")\n",
        "formatted_examples = []\n",
        "\n",
        "for qa_pair in tqdm(all_qa_pairs[:500], desc=\"Formatting examples\"):  # Limit for initial testing\n",
        "    formatted_text = format_for_instruction_tuning(qa_pair)\n",
        "    \n",
        "    # Check token length\n",
        "    tokens = tokenizer.tokenize(formatted_text)\n",
        "    if len(tokens) <= 2048:  # Limit to model's context length\n",
        "        formatted_examples.append({\n",
        "            'text': formatted_text,\n",
        "            'token_count': len(tokens)\n",
        "        })\n",
        "\n",
        "print(f\"Created {len(formatted_examples)} formatted examples for fine-tuning\")\n",
        "\n",
        "# Analyze token distributions\n",
        "if formatted_examples:\n",
        "    token_counts = [ex['token_count'] for ex in formatted_examples]\n",
        "    print(f\"\\nToken count statistics:\")\n",
        "    print(f\"  Mean: {np.mean(token_counts):.2f}\")\n",
        "    print(f\"  Median: {np.median(token_counts):.2f}\")\n",
        "    print(f\"  Max: {np.max(token_counts)}\")\n",
        "    print(f\"  Min: {np.min(token_counts)}\")\n",
        "else:\n",
        "    print(\"No examples created - check tokenizer setup\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. Split and Save Processed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split formatted examples into train/validation\n",
        "if formatted_examples:\n",
        "    train_texts = [ex['text'] for ex in formatted_examples]\n",
        "    train_split, val_split = train_test_split(train_texts, test_size=0.15, random_state=42)\n",
        "    \n",
        "    print(f\"Training examples: {len(train_split)}\")\n",
        "    print(f\"Validation examples: {len(val_split)}\")\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = Dataset.from_dict({'text': train_split})\n",
        "    val_dataset = Dataset.from_dict({'text': val_split})\n",
        "    \n",
        "    # Save datasets\n",
        "    train_dataset.save_to_disk('./processed_data/train')\n",
        "    val_dataset.save_to_disk('./processed_data/val')\n",
        "    \n",
        "    print(\"\\nDatasets saved successfully!\")\n",
        "    \n",
        "    # Save some metadata\n",
        "    metadata = {\n",
        "        'total_examples': len(formatted_examples),\n",
        "        'train_examples': len(train_split),\n",
        "        'val_examples': len(val_split),\n",
        "        'avg_token_length': np.mean(token_counts) if 'token_counts' in locals() else 0,\n",
        "        'max_token_length': np.max(token_counts) if 'token_counts' in locals() else 0,\n",
        "        'model_name': MODEL_NAME,\n",
        "        'dataset_source': 'ninadn/indian-legal',\n",
        "        'original_documents_processed': sample_size if 'sample_size' in locals() else 0\n",
        "    }\n",
        "    \n",
        "    with open('./processed_data/metadata.json', 'w') as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "    \n",
        "    print(\"Metadata saved!\")\n",
        "else:\n",
        "    print(\"No formatted examples to save. Check data processing steps.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Display sample formatted examples\n",
        "if formatted_examples:\n",
        "    print(\"Sample Formatted Examples for Fine-tuning:\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for i in range(min(2, len(formatted_examples))):\n",
        "        print(f\"\\n--- Example {i+1} ---\")\n",
        "        print(f\"Token count: {formatted_examples[i]['token_count']}\")\n",
        "        print(\"Content preview:\")\n",
        "        print(formatted_examples[i]['text'][:800] + \"...\")\n",
        "        print(\"\\n\" + \"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Summary\n",
        "\n",
        "This notebook has successfully:\n",
        "\n",
        "‚úÖ **Loaded and analyzed** the Indian Legal dataset (ninadn/indian-legal)  \n",
        "‚úÖ **Generated question-answer pairs** suitable for legal QA  \n",
        "‚úÖ **Formatted data** for instruction tuning with Mistral  \n",
        "‚úÖ **Split data** into training and validation sets  \n",
        "‚úÖ **Saved processed datasets** for fine-tuning  \n",
        "\n",
        "**Next Steps**: \n",
        "- Proceed to `2_fine_tuning.ipynb` to train the Mistral model\n",
        "- The processed data is ready for efficient fine-tuning with LoRA/QLoRA\n",
        "\n",
        "**Note**: This notebook processes a subset of the data for development. Increase `sample_size` for full dataset processing.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
